version: 2

default_workspace: &default_workspace
  # Smallest circleci official image at 11/17. We don't need any tools here.
  docker:
    - image: docker

save_cache:
  - &save_cache
    save_cache:
      key: n2k-cache-{{ .Branch }}-{{ .BuildNum }}
      paths:
        - docker-cache/built-images.tgz

restore_cache:
  - &restore_cache
    restore_cache:
      keys:
        - n2k-cache-{{ .Branch }}-
        - n2k-cache-


# Save all docker images in cache
save_docker_images:
  - &save_docker_images
    # Save tags & history. If you don't save history, can't re-use docker cache
    # Keep in sync the diff with load_docker_images
    run: |
      mkdir -p docker-cache
      docker images  --filter "dangling=false" --format '{{.ID}} {{.Repository}} {{.Tag}}' > docker_images.newsum
      if ! diff docker_images.newsum docker-cache/built-images.sum; then
        mv docker_images.newsum docker-cache/built-images.sum
        docker_images=$(docker images --filter 'dangling=false' \
          --format '{{.Repository}}:{{.Tag}}')
        docker_histories=$(for i in ${docker_images}; \
          do docker history -q $i | grep -v missing; \
        done)
        docker save ${docker_images} ${docker_histories} \
          | gzip > docker-cache/built-images.tgz
      fi

load_docker_images:
  - &load_docker_images
    # Keep in sync the summary generation with save_docker_images
    run: |
      if [[ -f docker-cache/built-images.tgz ]]; then
        zcat docker-cache/built-images.tgz | docker load;
        docker images  --filter "dangling=false" --format '{{.ID}} {{.Repository}} {{.Tag}}' > docker-cache/built-images.sum
      else
        echo "NO DOCKER CACHE";
      fi

jobs:
  # Check source format
  clang-format:
    docker:
      - image: alabate/clang-format
    steps:
      - checkout
      - run: |
            out="$(find . -name '*.c' -o -name '*.h' -exec bash -c \
              "diff  -Nu {} <(clang-format {} )" \;)"
            printf '%s' "$out"
            test -z "$out"


  # Build & prepare devel container
  build_dev:
    <<: *default_workspace
    steps:
      - setup_remote_docker
      - checkout
      # Use cached n2k images if possible
      - *restore_cache
      - *load_docker_images
      # Create development environment
      - run: apk add --no-cache make
      - run:
          environment:
            DOCKER_BUILD_PARAMETERS: -t n2k-dev
          command: make dev-docker
      - *save_docker_images
      - *save_cache


  # (Template) execute a single command in development docker
  T_dev_run: &T_dev_run
    <<: *default_workspace
    steps:
      - setup_remote_docker
      - checkout
      - *restore_cache
      - *load_docker_images
      - run: '[[ -f workspace.tgz ]] && tar xvzpf workspace.tgz || true'
      # sed: Don't want thread-safety test because musl bug
      - run: sed -i 's%\$(TESTS_\(DRD\|HELGRIND\)_XML)%%g' Makefile
      # Launch test kafka
      - run: docker run -d --hostname kafka --name kafka spotify/kafka;
      # Launch test container
      - run: docker run -dt --link kafka --name dev-container n2k-dev;
      # Copy environment
      - run: docker cp . dev-container:/app;
      # Actual commands run. Exit 255 will stop iteration
      - run: |
             printf "%s\n" "${docker_cmds}" | tr '\n' '\0' | \
               xargs -I {} -0 -t -n 1 docker exec dev-container sh -c '{} || exit 255'
      # Collect results
      - run: docker cp dev-container:/app/tests/ /tmp
      - run: docker cp dev-container:/app/coverage.out.html . || mkdir -p coverage.out.html
      - store_test_results:
          path: /tmp/tests
      - store_artifacts:
          path: coverage.out.html


  # Release build -> no asserts, optimizations on
  release:
    <<: *T_dev_run
    environment:
      - PYTEST_JOBS: 16
      - docker_cmds: |
          ./configure --bootstrap
          make
          make checks
          make memchecks

  # Test with assertions on
  assertions:
    <<: *T_dev_run
    environment:
      - PYTEST_JOBS: 16
      - PYTEST: py.test-3
      - docker_cmds: |
          ./configure --bootstrap --enable-assertions
          make
          make checks

  coverage:
    <<: *T_dev_run
    environment:
      - PYTEST_JOBS: 16
      - PYTEST: py.test-3
      - docker_cmds: |
          ./configure --bootstrap --disable-optimization --enable-coverage
          make
          make checks
          make memchecks
          make coverage

#
#  # Check source code
#  static-analyzer:
#    <<: *default_workspace
#    docker:
#      - image: alabate/clang-format
#    steps:
#      - setup_remote_docker
#      - run: |
#              apt update && apt install -y --no-install-recommends \
#              software-properties-common python-software-properties wget
#      - run: wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key|apt-key add -
#      - run: |
#              echo \
#              'deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-5.0 main' \
#              >> /etc/apt/sources.list
#      - run: |
#              apt update && \
#              apt install make gcc libz-dev clang-5.0 librdkafka-dev -y \
#                  --no-install-recommends
#      - run: docker cp static_analyzer:/app /home/circleci/workspace
#      - run: |
#              cd /home/circleci/workspace; \
#              find src/ -name '*.o' -delete; make src/version.h; \
#              scan-build-5.0 --status-bugs -o /tmp/scan-build make \
#              $(find src -name '*.c' -print | sed 's/\.c/\.o/;')
#
#      - store_artifacts:
#          path: /tmp/scan-build


workflows:
  version: 2
  binary:
    jobs:
      - clang-format

      # Base docker for build and tests application
      - build_dev

      - assertions:
          requires:
            - build_dev
      - release:
          requires:
            - build_dev
      - coverage:
          requires:
            - build_dev
      #- checks:
      #    requires:
      #      - make

      #
