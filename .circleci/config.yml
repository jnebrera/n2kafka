version: 2

default_workspace: &default_workspace
  # Smallest circleci official image at 11/17. We don't need any tools here.
  docker:
    - image: docker/compose:1.21.2

save_cache:
  - &save_cache
    save_cache:
      key: n2k-cache-{{ .Branch }}-{{ .BuildNum }}
      paths:
        - docker-cache/built-images.tgz

restore_cache:
  - &restore_cache
    restore_cache:
      keys:
        - n2k-cache-{{ .Branch }}-
        - n2k-cache-


# Save all docker images in cache
save_docker_images:
  - &save_docker_images
    # Save tags & history. If you don't save history, can't re-use docker cache
    # Keep in sync the diff with load_docker_images
    run: |
      mkdir -p docker-cache
      docker images  --filter "dangling=false" --format '{{.ID}} {{.Repository}} {{.Tag}}' | sort > docker_images.newsum
      if ! diff docker_images.newsum docker-cache/built-images.sum; then
        mv docker_images.newsum docker-cache/built-images.sum
        docker_images=$(docker images --filter 'dangling=false' \
          --format '{{.Repository}}:{{.Tag}}')
        docker_histories=$(for i in ${docker_images}; \
          do docker history -q $i | grep -v missing; \
        done)
        docker save ${docker_images} ${docker_histories} \
          | gzip > docker-cache/built-images.tgz
      fi

load_docker_images:
  - &load_docker_images
    # Keep in sync the summary generation with save_docker_images
    run: |
      if [[ -f docker-cache/built-images.tgz ]]; then
        zcat docker-cache/built-images.tgz | docker load;
        docker images  --filter "dangling=false" --format '{{.ID}} {{.Repository}} {{.Tag}}' | sort > docker-cache/built-images.sum
      else
        echo "NO DOCKER CACHE";
      fi

# Save n2kafka binary in to be used in another job
save_binary:
  - &save_binary
    run: |
      mkdir -p "/tmp/${CIRCLE_JOB}"
      cp n2kafka "/tmp/${CIRCLE_JOB}"

jobs:
  # Check source format
  clang-format:
    docker:
      - image: alabate/clang-format
    steps:
      - checkout
      - run: |
            out="$(find . -name '*.c' -o -name '*.h' -exec bash -c \
              "diff  -Nu {} <(clang-format {} )" \;)"
            printf '%s' "$out"
            test -z "$out"


  # Build & prepare devel container
  build_dev:
    <<: *default_workspace
    steps:
      - setup_remote_docker
      - checkout
      # Use cached n2k images if possible
      - *restore_cache
      - *load_docker_images
      # Create development environment
      - run: apk add --no-cache make
      - run:
          environment:
            DOCKER_BUILD_PARAMETERS: -t n2k-dev
          command: make dev-docker
      - *save_docker_images
      - *save_cache


  # (Template) execute a single command in development docker
  T_dev_run: &T_dev_run
    <<: *default_workspace
    steps:
      - setup_remote_docker
      - checkout
      - *restore_cache
      - *load_docker_images
      - run: '[[ -f workspace.tgz ]] && tar xvzpf workspace.tgz || true'
      # sed: Don't want thread-safety test because musl bug
      - run: sed -i 's%\$(TESTS_\(DRD\|HELGRIND\)_XML)%%g' Makefile
      # Launch test compose
      - run:
          background: true
          command:
            docker-compose -f tests/docker-compose.yml up
      # Wait container start & copy
      - run: |
          while ! docker cp . dev-container:/app; do :; done;

      # Actual commands run. Exit 255 will stop iteration
      - run: |
             export PYTEST_JOBS;
             printf "%s\n" "${docker_cmds}" | tr '\n' '\0' | \
               xargs -I {} -0 -t -n 1 docker exec dev-container sh -c '{} || exit 255'

      # Collect results
      - run:
          name: Save n2kafka binary & Makefile config for container creation
          command: |
            mkdir -p /tmp/bin/"${CIRCLE_JOB}" /tmp/config/"${CIRCLE_JOB}" &&
            docker cp dev-container:/app/n2kafka "/tmp/bin/${CIRCLE_JOB}" &&
            docker cp dev-container:/app/Makefile.config "/tmp/config/${CIRCLE_JOB}"
      - run: docker cp dev-container:/app/tests/ /tmp
      - run: docker cp dev-container:/app/coverage.out.html . || mkdir -p coverage.out.html
      - store_test_results:
          path: /tmp/tests
      - store_artifacts:
          path: coverage.out.html
      - persist_to_workspace:
          root: /tmp
          paths:
            - bin
            - config

  # Release build -> no asserts, optimizations on
  release:
    <<: *T_dev_run
    environment:
      - PYTEST_JOBS: 16
      - docker_cmds: |
          ./configure --bootstrap
          make

  # Test with assertions on
  assertions:
    <<: *T_dev_run
    environment:
      - docker_cmds: true

  coverage:
    <<: *T_dev_run
    environment:
      - PYTEST_JOBS: 16
      - PYTEST: py.test-3
      - docker_cmds: |
          ./configure --bootstrap --disable-optimization --enable-coverage
          make

  containers:
    docker:
      - image: google/cloud-sdk:alpine
    steps:
      - run: |
          apk add --no-cache git make binutils docker &&
          curl -s -L \
              "https://github.com/docker/compose/releases/download/1.21.2/docker-compose-$(uname -s)-$(uname -m)" \
              -o /usr/bin/docker-compose
      - setup_remote_docker
      - checkout
      - *restore_cache
      - *load_docker_images
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Gdb container
          # Get coverage binary, it is supposed to not to have any optimization
          # enabled
          command: |
            cp /tmp/workspace/bin/coverage/n2kafka \
              /tmp/workspace/config/coverage/Makefile.config . &&

            make -t gdb-docker && \
            CIRCLE_TAG=${CIRCLE_TAG//+/.} && \
            env DOCKER_OUTPUT_TAG=gcr.io/wizzie-registry/n2kafka \
              DOCKER_OUTPUT_VERSION=${CIRCLE_TAG:-latest}.gdb \
              make gdb-docker
      - run:
          name: Valgrind container
          # Get release binary
          command: |
            cp /tmp/workspace/bin/coverage/n2kafka \
              /tmp/workspace/config/coverage/Makefile.config . &&

            make -t valgrind-docker && \
            CIRCLE_TAG=${CIRCLE_TAG//+/.} && \
            env DOCKER_OUTPUT_TAG=gcr.io/wizzie-registry/n2kafka \
              DOCKER_OUTPUT_VERSION=${CIRCLE_TAG:-latest}.valgrind \
              make valgrind-docker
      - run:
          name: Release container
          # Get release binary
          command: |
            cp /tmp/workspace/bin/coverage/n2kafka . &&
            strip ./n2kafka && \

            make -t docker && \
            CIRCLE_TAG=${CIRCLE_TAG//+/.} && \
            env DOCKER_OUTPUT_TAG=gcr.io/wizzie-registry/n2kafka \
              DOCKER_OUTPUT_VERSION=${CIRCLE_TAG:-latest} \
              make docker
      - run:
          name: Upload images to gcr
          command: |
            # Do not print passwords!
            printf '+ docker gcloud login...\n' >&2
            GCLOUD_KEY_JSON=$(printf '%s' "$GCLOUD_SERVICE_KEY" | base64 -d)
            printf '%s' "$GCLOUD_KEY_JSON" \
              | docker login -u _json_key --password-stdin https://gcr.io

            printf '+ gcloud auth activate...\n' >&2
            # docker login -u $DOCKER_USER -p $DOCKER_PASS
            printf '%s' "$GCLOUD_KEY_JSON" | \
              gcloud auth activate-service-account --key-file=/dev/stdin

            set -x
            CIRCLE_TAG=${CIRCLE_TAG//+/.}
            gcloud config set project "$GCLOUD_PROJECT"
            gcloud auth configure-docker --quiet

            set -- '' '.gdb' '.valgrind'
            for ext in "$@"; do
              docker push -- gcr.io/wizzie-registry/n2kafka:${CIRCLE_TAG:-latest}"$ext"
            done

#
#  # Check source code
#  static-analyzer:
#    <<: *default_workspace
#    docker:
#      - image: alabate/clang-format
#    steps:
#      - setup_remote_docker
#      - run: |
#              apt update && apt install -y --no-install-recommends \
#              software-properties-common python-software-properties wget
#      - run: wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key|apt-key add -
#      - run: |
#              echo \
#              'deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-5.0 main' \
#              >> /etc/apt/sources.list
#      - run: |
#              apt update && \
#              apt install make gcc libz-dev clang-5.0 librdkafka-dev -y \
#                  --no-install-recommends
#      - run: docker cp static_analyzer:/app /home/circleci/workspace
#      - run: |
#              cd /home/circleci/workspace; \
#              find src/ -name '*.o' -delete; make src/version.h; \
#              scan-build-5.0 --status-bugs -o /tmp/scan-build make \
#              $(find src -name '*.c' -print | sed 's/\.c/\.o/;')
#
#      - store_artifacts:
#          path: /tmp/scan-build

# Need to mark all jobs needed to build containers
filter_version_tag: &filter_version_tag
  # Start with version-like
  filters: &version_tag_filter
    tags:
      only: /^[0-9]+\.[0-9]+\.[0-9]+.*/

uses_build_dev_workspace: &uses_build_dev_workspace
  requires:
    - build_dev

workflows:
  version: 2
  binary:
    jobs:
      - clang-format

      # Base docker for build and tests application
      - build_dev:
          <<: *filter_version_tag

      - assertions:
          <<: *uses_build_dev_workspace

      - release:
          <<: *uses_build_dev_workspace
          <<: *filter_version_tag

      - coverage:
          <<: *uses_build_dev_workspace
          <<: *filter_version_tag

      #- checks:
      #    requires:
      #      - make

      - containers:
          requires:
            - coverage
            - release
          filters:
            <<: *version_tag_filter
            branches:
              only: master
